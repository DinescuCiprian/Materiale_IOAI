{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7386296,"sourceType":"datasetVersion","datasetId":2109585}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 1. Încărcarea și curățarea datelor: Vom citi fișierul JSON și\n# vom extrage datele relevante. De asemenea, vom gestiona datele\n# lipsă și vom transforma diverse tipuri de date într-un format\n# potrivit pentru antrenare.\n\n# 2. Explorarea datelor: Vom analiza distribuția variabilelor și \n# vom identifica eventualele outliers și dezechilibre în date.\n\n# 3. Feature engineering: Vom crea caracteristici (features) \n# utile pentru antrenarea modelului, evitând pe cât posibil \n# folosirea textului din review-uri în această etapă inițială.\n\n# 4. Antrenarea și evaluarea modelului: Vom folosi metode de \n# machine learning și deep learning pentru a antrena \n# modele și a evalua performanța acestora.\n\n# 5. Optimizarea modelului: Vom ajusta parametrii și vom \n# experimenta cu diferite modele pentru a îmbunătăți \n# acuratețea predicțiilor.\n\n# Partea de cod începe acum:\n# 1. Încărcarea și curățarea datelor. Începem prin a citi și a\n# curăță din fișierul JSON:\nimport os\nimport json\nimport pandas as pd\n\n# Citim datele din fișierul JSON\ndef load_data(file_path):\n    with open(file_path, 'r', encoding='utf-8') as finp:\n        data = json.load(fin)\n    return data\n\nfile_path = 'games.json'\ndata = load_data(file_path)\n\n# Transformăm datele într-un DataFrame pentru o analiză mai ușoară\ngames_list = []\n\nfor appID, game in data.items():\n    game_info = {\n        'appID': appID,\n        'name': game['name'],\n        'releaseDate': game['release_date'],\n        'estimatedOwners': game['estimated_owners'],\n        'peakCCU': game['peak_ccu'],\n        'required_age': game['required_age'],\n        'price': game['price'],\n        'dlcCount': game['dlc_count'],\n        'longDesc': game['detailed_description'],\n        'shortDesc': game['short_description'],\n        'languages': game['supported_languages'],\n        'fullAudioLanguages': game['full_audio_languages'],\n        'reviews': game['reviews'],\n        'headerImage': game['header_image'],\n        'website': game['website'],\n        'supportWeb': game['support_url'],\n        'supportEmail': game['support_email'],\n        'supportWindows': game['windows'],\n        'supportMac': game['mac'],\n        'supportLinux': game['linux'],\n        'metacriticScore': game['metacritic_score'],\n        'metacriticURL': game['metacritic_url'],\n        'userScore': game['user_score'],\n        'positive': game['positive'],\n        'negative': game['negative'],\n        'scoreRank': game['score_rank'],\n        'achievements': game['achievements'],\n        'recommendations': game['recommendations'],\n        'notes': game['notes'],\n        'averagePlaytime': game['average_playtime_forever'],\n        'averageplaytime2W': game['average_playtime_2weeks'],\n        'medianPlaytime': game['median_playtime_forever'],\n        'medianPlaytime2W': game['median_playtime_2weeks'],\n        'developers': game['developers'],\n        'publishers': game['publishers'],\n        'categories': game['categories'],\n        'genres': game['genres'],\n        'screenshots': game['scrennshots'],\n        'movies': game['movies'],\n        'tags': game['tags']\n    }\n    games_list.append(game_info)\n    \ngame_df = pd.DataFrame(games_list)\n\n# Vizualizăm primele rânduri ale DataFrame-ului\nprint(games_df.head())\n\n# 2. Explorarea datelor\n# Vom analiza distribuția datelor și vom vizualiza relațiile \n# dintre variabile pentru a înțelege mai bine structura setului de date:\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Conversia coloanelor numerice la tipul potrivit\ngames_df['price'] = pd.to_numeric(games_df['price'], errors='coerce')\ngames_df['peakCCU'] = pd.to_numeric(games_df['peak_ccu'], errors='coerce')\ngames_df['required_age'] = pd.to_numeric(games_df['required_age'], errors='coerce')\ngames_df['metacriticScore'] = pd.to_numeric(games_df['metacritic_score'], errors='coerce')\ngames_df['userScore'] = pd.to_numeric(games_df['user_score'], errors='coerce')\ngames_df['positive'] = pd.to_numeric(games_df['positive'], errors='coerce')\ngames_df['negative'] = pd.to_numeric(games_df['negative'], errors='coerce')\ngames_df['achievements'] = pd.to_numeric(games_df['achievements'], errors='coerce')\ngames_df['recommendations'] = pd.to_numeric(games_df['recommendations'], errors='coerce')\ngames_df['averagePlaytime'] = pd.to_numeric(games_df['average_playtime_forever'], errors='coerce')\ngames_df['averageplaytime2W'] = pd.to_numeric(games_df['average_playtime_2weeks'], errors='coerce')\ngames_df['medianPlaytime'] = pd.to_numeric(games_df['median_playtime_forever'], errors='coerce')\ngames_df['medianPlaytime2W'] = pd.to_numeric(games_df['median_playtime_2weeks'], errors='coerce')\ngames_df['dlcCount'] = pd.to_numeric(games_df['dlc_count'], errors='coerce')\n\n# Vizualizarea distribuției prețurilor\nplt.figure(figsize=(10,6))\nsns.histplot(games_df['price'], bins=50, kde=True)\nplt.title('Distribuția prețurilor jocurilor')\nplt.xlabel('Preț (USD)')\nplt.ylabel('Frecvența')\nplt.show()\n\n# Vizualizarea relației dintre preț și numărul de jucători concurenți\nplt.figure(figsize=(10,6))\nsns.scatterplot(data=games_df, x='peakCCU',y='price')\nplt.title('Relația dintre numărul de jucători concurenți și preț')\nplt.xlabel('Numărul de jucători concurenți(peakCCU)')\nplt.ylabel('Preț (USD)')\nply.show()\n\n# 3 Feature engineering\n# Vom transforma datele textuale și categorice în format \n# numeric, folosind tehnici precum one-hot encoding pentru \n# limbile suportate și genuri, și vom trata datele lipsă.\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.impute import SimpleImputer\n\n# Codificarea limbilor suportate\nlanguages = games_df['languages'].str.get_dummies(sep=',')\ngames_df = pd.concat([games_df,languages], axis=1)\n\n# Codificarea genurilor\ngenres = games_df['genres'].str.get_dummies(sep=',')\ngames_df = pd.concat([games_df, genres], axis=1)\n\n# Tratamentul valorilor lipsă\nimputer = SimpleImputer(strategy='mean')\ngames_df['price'] = imputer.fit_transform(games_df[['price']])\n\n# Selectarea caracteristicilor relevante pentru antrenare\nfeature = games_df[['peakCCU', 'required_age', 'dlcCount', 'metacriticScore', 'userScore', 'positive', 'negative', 'achievements', 'recommendations', 'averagePlaytime', 'averageplaytime2W', 'medianPlaytime', 'medianPlaytime2W'] + list(languages.columns) + list(genres.columns)]\ntarget = games_df['price']\n\n# 4. Antrenarea și evaluarea modelului\n# Vom folosi metode de machine learning pentru a antrena un \n# model și vom evalua performanța acestuia.\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\n# Împărțirea datelor în seturi de antrenament și testare\nX_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n\n# Antrenarea unui model RandomForest\nmodel = RandomForestRegressor(n_estimators=100, random_state=42)\nmodel.fit(X_train, y_train)\n\n# Predicția pe setul de testare\ny_pred = model.predict(X_test)\n\n# Evaluarea performanței modelului\nmse = mean_squared_error(y_test, y_pred)\nrmse = mse ** 0.5\nprint(f'Root Mean Squared Error: {rmse}')\n\n# 5. Optimizarea modelului\n# Vom ajusta parametrii și vom experimenta cu diferite \n# modele pentru a îmbunătăți performanța.\n\nfrom sklearn.model_selection import GridSearchCV\n\n# Optimizarea modelului RandomForest folosind GridSearchCV\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [None, 10, 20, 30],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4]\n}\ngrid_search = GridSearchCV(estimator=model,\n\n\n\n\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]}]}